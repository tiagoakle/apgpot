%{
\documentclass[smallextended]{article}       % onecolumn (second format)
%\documentclass[smallextended]{svjour3}       % onecolumn (second format)

%\smartqed  % flush right qed marks, e.g. at end of proof

\usepackage{graphicx,bbm,algorithmic,algorithm} 
\usepackage{amsmath,amstext,amssymb,amsfonts,amscd,comment}

%\spnewtheorem{defn}{Definition}{\bf}{\rm} 
\newcounter{rulenum} 
\newcounter{sent} 
\newcounter{tempcnt} 

\include{macros}
\title{Notes on Accelerated Proximal Gradient Algorithms for Potential-reduction, form the
work of Yinyu Ye and Anders Skajaa}
%\title{Notes on Accelerated Proximal Gradient Algorithms for Potential-reduction}
\author{
   %Anders Skajaa
   %\and Yinyi Ye 
   %\and Santiago Akle
   Santiago Akle.
}

%\institute{A. Skajaa \at
%           Dtu
%        \\ \email{andsk@imm.dtu.dk}
%           \and
%           Y. Ye \at
%           Dept of Management Science and Engineering, Stanford University, Stanford, CA 94305
%        \\ \email{yinyu-ye@stanford.edu}
%           \and
%           S. Akle \at
%           ICME, Stanford University, Stanford, CA 94305
%        \\ \email{akle@stanford.edu}
%
\begin{document}
\maketitle

Let $f:\Re^n\to(-\infty,\infty]$ be a proper convex differentiable function
with Lipschitz continuous gradient of constant $L$. Furthermore let
\[0 < f\] except maybe for some set $X^{\star}$ where $f(x^\star) = 0$.

Given a convex function $h$ its $\prx$ operator is the mapping defined by
\[
\prx_{h}(y) = \arg \min_u\left\{h(u) + \frac{1}{2}\n{y-u}\right\}.
\]

The potential function $\psi$ is defined by
\[
\psi := \rho \log{f} - \sum_{i\in I}\log{x},
\]
where $I\subseteq [n]$ is an index set and $\rho$ is a scalar.

Denote by
$g = \rho \log{f}$ and by $h = -\sum_{i\in I} \log{x}$. 
With this notation $\phi = g+h$.

The potential proximal gradient algorithm is given by the repetitive application
of the $\prx$ operator for the convex function $t_kh$ where $t_k$ is a
positive step size.

We state the algoithm formally here.

\begin{algorithm}
  \caption{Potential Reduction Proximal Gradient}
  \begin{algorithmic}
  \STATE $k \gets 0, x \gets x_0, t_k \gets t_0$

  \WHILE{$f(x_k)- f^* > \epsilon$}
    \STATE $x_{k+1} = \prx_{t_kh}{x_k - t_k \nabla g(x_k)}$
  \ENDWHILE
  \end{algorithmic}
  \label{alg:ppg}
\end{algorithm}


Denote by $\ell(x;y)$ the local model of $\psi$ at $y$ given by
\[
\ell(x;y) = g(y) + \nabla g(y)^T(x-y) +  h(x),
\]
and denote by $G_t(x) = \frac{1}{t}(\xp - x)$. 
The algorithm update is given by $\xp = x-tG_t(x)$.

\begin{clm}
The proximal gradient update is 
\[
    \xp = \arg \min_u\left\{ \ell(u;x) + \frac{1}{2t}\n{x-u} \right\}.
\] 
\end{clm}

\begin{prf}
  Observe that the argument of the minimization achieves its minimum at a 
  point where $x_I>0$. Therefore $h$ is differentiable at the minimizer.
  Using the first order optimality conditions we can conclude that
  \[
  \nabla g(\xp) + \frac{1}{t}\left( \xp - y \right) + \nabla h(\xp)= 0.
  \]
  Therefore $\xp$ also satisfies the optimality conditions of the problem 
  \[
  \xp = \arg \min_u \left\{ h(u) + \frac{1}{t}\n{u - x + t\nabla g}^2 \right\} 
      = \arg \min_u\left\{ th(u) + \n{u - x + t\nabla g}^2 \right\} 
      = \prx_{th}\left\{ x - t\nabla g \right\}.
  \] 
\end{prf}

Observe that the gradients of $f$ and $g$ are related by $\nabla g(x) = \frac{\rho}{f(x)}\nabla f(x)$.
Therefore we can re write the proximal algorithm in terms of steps allong the vector
$\nabla f$ rather than $\nabla g$. 

More formally: define the algorithm
\begin{algorithm}
  \caption{Alternative form of the Potential Reduction Proximal Gradient}
  \begin{algorithmic}
  \STATE $k \gets 0, x \gets x_0, r_k \gets t_0$

  \WHILE{$f(x_k)- f^* > \epsilon$}
    \STATE $x_{k+1} = \prx_{r_kf(x_k)/\rho h}{x_k - r_k \nabla f(x_k)}$
  \ENDWHILE
  \end{algorithmic}
  \label{alg:ppf}
\end{algorithm}

In particular 
\begin{clm}
if algorithm \eqref{alg:ppg} is executed with the sequence of 
step sizes $\left\{ t_k \right\}$ then algorithm \eqref{alg:ppf} with 
the sequence of step sizes $\left\{ r_k = t_k \frac{\rho}{f(x_k)}\right\}$ will generate the same iterates.

\end{clm}
\begin{prf}
 Observe that 
 \begin{align*}
   \xp = \prx_{t_kh}\left\{x_k - t_k \nabla g(x_k)\right\} & = \arg \min_u \left\{ t_kh(u) + \frac{1}{2}\n{x_k - t_k \nabla g(x_k)-u}^2 \right\} \\
   & = \arg \min_u \left\{ r_k\frac{f(x_k)}{\rho}h(u) + \frac{1}{2}\n{x_k - r_k\frac{f(x)}{\rho} \nabla g(x_k)-u}^2 \right\} \\
   & = \arg \min_u \left\{ r_k\frac{f(x_k)}{\rho}h(u) + \frac{1}{2}\n{x_k - r_k\nabla f(x_k)-u}^2 \right\} \\
   & = \prx_{r_k\frac{f(x_k)}{\rho}h}\left\{x_k - r_k\nabla f(x_k)\right\}
 \end{align*} 
 \end{prf} 

 Let me venture an interpretation of the proximal gradient potential reduction algorithm:
 If we denote by $\mu = \frac{f(x)}{\rho}$ then $\mu h(x)$ is amenable to a barrier function. 
 The steps $\hat x = x - r_k\nabla f$ are descent steps on the objective and $\xp = \prx_{r_k \mu h}{\hat x}$ act
 like centering steps.

 \section{Solving Linear Programs}

 To use the potential reduction model for solving Linear Programs, 
 we have several choices of objective function:
 \[
 f_1(x,y,z) = \n{Ax-b}^2 + \n{A^Ty+z-c}^2 + (c^Tx-b^Ty)^2,
 \]
 let 
  \[
 f_2(x,y,z) = \n{Ax-b}^2 + \n{A^Ty+z-c}^2 + x^Tz,
 \]
 and let
  \[
 f_3(x,\tau,y,z,\kappa) = \n{Ax-\tau b}^2 + \n{A^Ty+z-\tau c}^2 + (c^Tx-b^Ty+\kappa)^2.
 \]
 
  When restricted to the positive orthant, these are clearly convex non-negative 
  and if the linear problem is feasible, and bounded, they take the value 0 at the
  solution of the linear program.

 \subsection{The accelerated proximal potential algorithm}

 For any of the $f_i$ above, if a triplet $(x^\star,y^\star,z^\star)$ is found such that $f(x^\star,y^\star,z^\star)=0$ and $0\leq x^\star,z^\star$,
 then cleary it is a solution. Therefore we can re write it as the convex problem

 \begin{align*}
   \min f\\
   \st 0\leq x,z
 \end{align*}
 
 Or using the notation $I_[x,z](x,z)$ for the indicator function of the positive orthant of the variables
 $x$ and $z$, we can re write it as 

 \begin{align*}
   \min f + I
 \end{align*}


 An evident choice of algorithm for the above formulation would
 be the accelerated proximal gradient. 

 \begin{algorithm}
  \caption{Proximal Gradient}
  \begin{algorithmic}
  \STATE $k \gets 0, x \gets x_0, r_k \gets t_0$
  \WHILE{$f(x_k)- f^* > \epsilon$}
  \STATE $x_{k+1} = \prx_{t_k I_{\Re^{+}}}{\left(x_k - t_k \nabla f(x_k)  \right)}$
  \ENDWHILE
  \end{algorithmic}
  \label{alg:pg}
\end{algorithm}

To compare the behavior of an accelerated proximal gradient algorithm against 
 the accelerated proximal potential algorithm, a small 
 primal dual feasible random problem was generated. The choice $\rho = n+\sqrt n$ was 
 used and both algorithms were initialized witht the same starting point and backtracking parameters.

 \begin{figure}[h]
   \begin{center}
     \includegraphics[scale=0.5]{./Images/potvsprox.png}
   \end{center}
   \caption{Value of objective vs iteration for APP and APG}
   \label{fig:APPvsAPG}
 \end{figure}
 Figure \eqref{fig:APPvsAPG} plots the values of $f_1$ across iteration count, it is 
 not clear that the proximal potential algorithm produces a faster convergence rate
 than the regular accelerated projected gradient.

 \begin{figure}[h]
   \begin{center}
     \includegraphics[scale=0.5]{./Images/potvsrho.png}
   \end{center}
   \caption{Dependence on $\rho$}
   \label{fig:APPvsRho}
 \end{figure}

 This could be dependent on the choice of $\rho$, but as figure \eqref{fig:APPvsRho} shows 
 all choices of $\rho$ are slower than the indicator function projection.

\begin{figure}[h]
   \begin{center}
     \includegraphics[scale=0.5]{./Images/potvsproxvsapgpot.png}
   \end{center}
   \caption{Comparisson to apgpot}
   \label{fig:APPvsAPGPOT}
 \end{figure}

To rule out a bug in the implementation, I compare it to apgpot, figure \eqref{fig:APPvsAPGPOT}.

\section{Solving LPs with first order methods}
To use the first order method machinery, we must translate linear programs into
the $\psi = g+h$ form with $g,h$ convex with $\nabla g$ Lipschitz continuous.

For the following discussion consider the problem \eqref{eq:primal_standard} in standard form
\begin{align}
  \minimize{x}{c^Tx}\\
  \st Ax=b,\\
    0\leq x
    \tag{P}
  \label{eq:primal_standard}
\end{align}

\subsection{TFOCS default formulation}
The default construction in TFOCS regularizes a problem in 
standard form to create the problem
\begin{align*}
  \minimize{x}{c^Tx + \mu/2\n{x}^2_2},
  \st Ax=b,\\
      0\leq x,
  \label{eq:primal_reg}
  \tag{Pr}
\end{align*}
with dual
\begin{align*}
  \minimize{y,z}{\frac{1}{2\mu}\n{A^Ty+z-c}_2^2-b^Ty} \\
  \st 0\leq z,
  \label{eq:dual_reg}
  \tag{Dr}
\end{align*}
which can be readily minimized using an accelerated projected gradient method.
One can alternatively solve the problems
\begin{align*}
  \minimize{x}{\frac{1}{2\mu}\n{Ax-b}_2^2} + c^Tx\\
  \st 0\leq x,
  \label{eq:primal_reg_un}
  \tag{Pru}
\end{align*}
or 
\begin{align*}
  \minimize{x,y,z}{\frac{1}{2\mu}\n{A^Ty+z-c}_2^2 + \frac{1}{2\mu}\n{Ax-b}_2^2 + c^Tx-b^Ty}\\
  \st 0\leq x,z,
  \label{eq:primal_dual_reg}
  \tag{PDr}
\end{align*}
which can also be minimized using accelerated projected gradient.

\subsection{Formulation by Lan Lu and Monteiro}
Using the primal-dual formulation one can avoid regularization and solve problem \eqref{eq:primal_standard} exactly,
while incurring a larger cost per iteration when comparing to \eqref{eq:primal_reg_un} or \eqref{eq:dual_reg}.
\begin{align}
  \minimize{x,y,z}{\n{Ax-b}_2^2+\n{A^Ty+z-c}_2^2+(c^Tx-b^Ty)^2}\\
  \st 0\leq x,z.
  \label{eq:primal_dual}
  \tag{PD}
\end{align}

This is clearly the same as using accelerated proximal gradient with objective $f_1$.

\subsection{Homogeneous self dual model and infeasibility detection}

If one can solve the problem
\begin{align}
  \minimize{x,y,z}{\n{Ax-\tau b}_2^2+\n{A^Ty+z-\tau c}_2^2+(c^Tx-b^Ty+\kappa)^2}\\
  \st 0\leq x,z,\tau,\kappa.
  \label{eq:hsd}
  \tag{HSD}
\end{align}
then one can use its structure to detect infeasibility. 

The following two are a random example and an LPnetlib example. 
The random example follows the sparsity pattern of the LPnetlib problem,
it was generated with 
$m=524,n=1028$, the non zero entries fo matrix $A$ have standard normal deviation. The
feasible primal dual pairs were generated with $x,y$ normaly distributed
and $z$ uniform in $(0,1]$.

\begin{comment}
%}
The following are generated from the tfocs_homogeneous_test.m script
%{
\end{comment}


\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.5]{./Images/hsd_llm_primal_dual_infeas.png}
  \end{center}
  \caption{HSD Primal and Dual infeasibility vs iteration}
  \label{fig:hsd_pd_infeas}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.5]{./Images/hsd_llm_tau_over_kappa.png}
  \end{center}
  \caption{HSD $\tau/\kappa$ vs iteration}
  \label{fig:hsd_tau_kappa}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.5]{./Images/hsd_llm_centrality.png}
  \end{center}
  \caption{Centrality measure $x'z+\kappa\tau$}
  \label{fig:hsd_centrality}
\end{figure}

\subsection{Example from lpnetlib problem }

\begin{comment}
%}
The following are generated by the 
tfocs_homogeneous_compare_rand_lpnetlib.m scripts
%{
\end{comment}


\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.5]{./Images/hsd_llm_primal_dual_infeas_lpnetlib.png}
  \end{center}
  \caption{HSD Primal and Dual infeasibility vs iteration}
  \label{fig:hsd_pd_infeas_lpnetlib}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.5]{./Images/hsd_llm_tau_over_kappa_lpnetlib.png}
  \end{center}
  \caption{HSD $\tau/\kappa$ vs iteration}
  \label{fig:hsd_tau_kappa_lpnetlib}
\end{figure}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.5]{./Images/hsd_llm_centrality_lpnetlib.png}
  \end{center}
  \caption{Centrality measure $x^Tz+\kappa\tau$}
  \label{fig:hsd_centrality_lpnetlib}
\end{figure}



\subsection{Non-convex potential gradient projection}
An alternative approach is to split the function $\psi$ 
by $g=\rho\log{f} - \frac{1}{2}\sum_{i\in I}\log{x}$ and
$h = - \frac{1}{2}\sum_{i\in I}\log{x}$.

Setting $f = \n{Ax-b}_2^2+\n{A^Ty+z-c}_2^2+(c^Tx-b^Ty)^2$, 
if the algoritm is useful it will converge to a solution of the LP.

\subsection{Comparing LLM Proximal Potential Projection and Potential Gradient}

The following example shows the behavior of the LLM algorithm allong with 
the proximal potential and the potential-gradient approaches.
\begin{itemize}
  \item $m=524$
    \item $n=1028$
      \item $2\%$ non zero entries 
\end{itemize}

\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.5]{./Images/llm_potgrad_proxpot.png}
  \end{center}
  \caption{Decay of llm potgrad and proxpot}
  \label{fig:llm_potgrad_proxpot}
\end{figure}

\begin{comment}
Generated by experiment compare_llm_proxpot_potgrad.m
\end{comment}

\end{document}
%}
